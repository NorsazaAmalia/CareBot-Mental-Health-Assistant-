{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vyEvUYSI928q"
      },
      "outputs": [],
      "source": [
        "# use natural language toolkit\n",
        "import nltk\n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "# word stemmer\n",
        "stemmer = LancasterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3 classes of training data\n",
        "training_data = []\n",
        "# capture unique stemmed words in the training corpus\n",
        "corpus_words = {}\n",
        "class_words = {}"
      ],
      "metadata": {
        "id": "LzsaP7c3-6Uq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_data():\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"alright\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"ok\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"okay\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"amazing\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"appreciate\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"awesome\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"balanced\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"beautiful\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"best\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"blessed\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"bliss\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"bright\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"brilliant\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"brisk\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"calm\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"capable\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"careful\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"caring\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"cautious\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"charming\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"cheerful\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"clever\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"committed\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"communicative\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"compassionate\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"competent\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"competitive\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"complete\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"confident\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"conscientious\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"considerate\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"consistent\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"constructive\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"cooperative\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"courage\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"determined\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"devoted\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"easy\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"efficient\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"effortless\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"excellent\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"excitement\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"fascinating\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"fine\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"fortunate\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"fulfilled\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"fun\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"excitement\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"glad\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"good\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"natural\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"great\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"happy\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"impressive\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"incredible\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"inspired\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"interesting\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"joy\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"kind\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"knowledgable\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"learning\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"like\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"love\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"lucky\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"magical\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"marvellous\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"mastered\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"merry\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"mighty\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"motivated\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"natural\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"nice\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"outgoing\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"passionate\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"peaceful\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"perfect\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"pleasing\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"polite\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"precise\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"prepared\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"productive\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"progressive\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"prosperous\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"proud\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"refreshing\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"relax\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"reliable\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"relieved\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"respect\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"safe\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"satisfied\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"secure\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"sincere\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"smart\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"sociable\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"special\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"spectacular\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"sophisticated\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"super\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"surprised\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"thrilling\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"thriving\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"trust\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"understanding\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"well\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"wise\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"wonderful\"})\n",
        "    training_data.append({\"class\":\"positive\", \"sentence\":\"worth\"})"
      ],
      "metadata": {
        "id": "OtWm73w6_Aha"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    training_data.append({\"class\":\"greetings\", \"sentence\":\"Hi\"})\n",
        "    training_data.append({\"class\":\"greetings\", \"sentence\":\"Hello\"})\n",
        "    training_data.append({\"class\":\"greetings\", \"sentence\":\"sup\"})\n",
        "    training_data.append({\"class\":\"greetings\", \"sentence\":\"what's up\"})\n",
        "    training_data.append({\"class\":\"greetings\", \"sentence\":\"wazzup\"})"
      ],
      "metadata": {
        "id": "Ax3HbHN5_KfC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    training_data.append({\"class\":\"thanks\", \"sentence\":\"thanks\"})\n",
        "    training_data.append({\"class\":\"thanks\", \"sentence\":\"grateful\"})\n",
        "    training_data.append({\"class\":\"thanks\", \"sentence\":\"appreciate\"})\n",
        "    training_data.append({\"class\":\"thanks\", \"sentence\":\"gratitude\"})\n",
        "    training_data.append({\"class\":\"thanks\", \"sentence\":\"nice\"})"
      ],
      "metadata": {
        "id": "H31sQ7IO_QMz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    training_data.append({\"class\":\"quit\", \"sentence\":\"Honestly, I fell like I'd like to quit schooling.\"})"
      ],
      "metadata": {
        "id": "1sSbkVi7_roW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    training_data.append({\"class\":\"test\", \"sentence\":\"i want to take a test\"})\n",
        "    training_data.append({\"class\":\"test\", \"sentence\":\"i want to choose a test\"})\n",
        "    training_data.append({\"class\":\"test\", \"sentence\":\"i want to directly take a test\"})"
      ],
      "metadata": {
        "id": "ZH3YD0IW_bFj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    training_data.append({\"class\":\"anxietytest\", \"sentence\":\"anxiety test\"})\n",
        "    training_data.append({\"class\":\"anxietytest\", \"sentence\":\"1\"})  \n",
        "    training_data.append({\"class\":\"stresstest\", \"sentence\":\"stress test\"})\n",
        "    training_data.append({\"class\":\"stresstest\", \"sentence\":\"2\"})  \n",
        "    training_data.append({\"class\":\"depressiontest\", \"sentence\":\"depression\"})\n",
        "    training_data.append({\"class\":\"depressiontest\", \"sentence\":\"3\"})  "
      ],
      "metadata": {
        "id": "Doi5vvXi_vWB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    training_data.append({\"class\":\"give\", \"sentence\":\"Give out symptom to chatbot for assessment\"})"
      ],
      "metadata": {
        "id": "TNDpty2W_1oL"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    training_data.append({\"class\":\"depression\", \"sentence\":\"not having interest\"})\n",
        "    training_data.append({\"class\":\"depression\", \"sentence\":\"lost interest\"})\n",
        "    training_data.append({\"class\":\"depression\", \"sentence\":\"sad\"})\n",
        "    training_data.append({\"class\":\"depression\", \"sentence\":\"change appetite\"})\n",
        "    training_data.append({\"class\":\"depression\", \"sentence\":\"depressed\"})\n",
        "    training_data.append({\"class\":\"depression\", \"sentence\":\"doesn't care\"})\n",
        "    training_data.append({\"class\":\"depression\", \"sentence\":\"weight loss\"})\n",
        "    training_data.append({\"class\":\"depression\", \"sentence\":\"loss appetite\"})\n",
        "    training_data.append({\"class\":\"depression\", \"sentence\":\"dont have appetite\"})\n",
        "    training_data.append({\"class\":\"depression\", \"sentence\":\"can't sleep\"})\n",
        "    training_data.append({\"class\":\"depression\", \"sentence\":\"feel tired\"})\n",
        "    training_data.append({\"class\":\"depression\", \"sentence\":\"no energy\"})\n",
        "    training_data.append({\"class\":\"depression\", \"sentence\":\"loss of energy\"})\n",
        "    training_data.append({\"class\":\"depression\", \"sentence\":\"easily to irritate\"})\n",
        "    training_data.append({\"class\":\"depression\", \"sentence\":\"useless\"})\n",
        "    training_data.append({\"class\":\"depression\", \"sentence\":\"lonely\"})\n",
        "    training_data.append({\"class\":\"depression\", \"sentence\":\"worthless\"})\n",
        "    training_data.append({\"class\":\"depression\", \"sentence\":\"pathetic\"})\n",
        "    training_data.append({\"class\":\"depression\", \"sentence\":\"helpless\"})\n",
        "    training_data.append({\"class\":\"depression\", \"sentence\":\"hopeless\"})\n",
        "    training_data.append({\"class\":\"depression\", \"sentence\":\"can't think properly\"})\n",
        "    training_data.append({\"class\":\"depression\", \"sentence\":\"can't concentrate\"})\n",
        "    training_data.append({\"class\":\"depression\", \"sentence\":\"make reckless decisions\"})\n",
        "    training_data.append({\"class\":\"depression\", \"sentence\":\"thinking of death or thinks about dying or attempts to suicide\"})\n",
        "    training_data.append({\"class\":\"depression\", \"sentence\":\"thinking about dying jumping at the highest floor\"})\n",
        "    training_data.append({\"class\":\"depression\", \"sentence\":\"trouble sleeping\"})\n",
        "    training_data.append({\"class\":\"depression\", \"sentence\":\"sleeping too much\"})\n",
        "    training_data.append({\"class\":\"depression\", \"sentence\":\"increase fatigue\"})\n",
        "    training_data.append({\"class\":\"depression\", \"sentence\":\"Increase in purposeless physical activity\"})\n",
        "    training_data.append({\"class\":\"depression\", \"sentence\":\"guilty\"})\n",
        "    training_data.append({\"class\":\"depression\", \"sentence\":\"difficulty thinking\"})\n",
        "    training_data.append({\"class\":\"depression\", \"sentence\":\"depress\"})"
      ],
      "metadata": {
        "id": "lvVxG1QH_5um"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    training_data.append({\"class\":\"anxiety\", \"sentence\":\"anxiety\"})\n",
        "    training_data.append({\"class\":\"anxiety\", \"sentence\":\"nervous\"})\n",
        "    training_data.append({\"class\":\"anxiety\", \"sentence\":\"restless\"})\n",
        "    training_data.append({\"class\":\"anxiety\", \"sentence\":\"tense\"})\n",
        "    training_data.append({\"class\":\"anxiety\", \"sentence\":\"sense of impending danger\"})\n",
        "    training_data.append({\"class\":\"anxiety\", \"sentence\":\"sense of panic\"})\n",
        "    training_data.append({\"class\":\"anxiety\", \"sentence\":\"sense of doom.\"})\n",
        "    training_data.append({\"class\":\"anxiety\", \"sentence\":\"increased heart rate.\"})\n",
        "    training_data.append({\"class\":\"anxiety\", \"sentence\":\"Sweating easily\"})\n",
        "    training_data.append({\"class\":\"anxiety\", \"sentence\":\"Trembling with no reason\"})\n",
        "    training_data.append({\"class\":\"anxiety\", \"sentence\":\"weak\"})\n",
        "    training_data.append({\"class\":\"anxiety\", \"sentence\":\"tired\"})\n",
        "    training_data.append({\"class\":\"anxiety\", \"sentence\":\"Trouble concentrating\"})\n",
        "    training_data.append({\"class\":\"anxiety\", \"sentence\":\"thinking about anything other than the present worry\"})\n",
        "    training_data.append({\"class\":\"anxiety\", \"sentence\":\"trouble sleeping\"})\n",
        "    training_data.append({\"class\":\"anxiety\", \"sentence\":\"Experiencing gastrointestinal (GI) problems\"})\n",
        "    training_data.append({\"class\":\"anxiety\", \"sentence\":\"difficulty controlling worry\"})\n",
        "    training_data.append({\"class\":\"anxiety\", \"sentence\":\"Having the urge to avoid things that trigger anxiety\"})\n",
        "    training_data.append({\"class\":\"anxiety\", \"sentence\":\"intense panic\"})\n",
        "    training_data.append({\"class\":\"anxiety\", \"sentence\":\"sudden feelings of intense anxiety and fear or terror\"})\n",
        "    training_data.append({\"class\":\"anxiety\", \"sentence\":\"worrying\"})\n",
        "    training_data.append({\"class\":\"anxiety\", \"sentence\":\"interfering with my work\"})\n",
        "    training_data.append({\"class\":\"anxiety\", \"sentence\":\"my fear, worry or anxiety upsetting to me and difficult to control\"})"
      ],
      "metadata": {
        "id": "a9w3D3cGABw8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    training_data.append({\"class\":\"stress\", \"sentence\":\"headache\"})\n",
        "    training_data.append({\"class\":\"stress\", \"sentence\":\"overeating\"})\n",
        "    training_data.append({\"class\":\"stress\", \"sentence\":\"stress stressing stressed\"})\n",
        "    training_data.append({\"class\":\"stress\", \"sentence\":\"undereating\"})\n",
        "    training_data.append({\"class\":\"stress\", \"sentence\":\"muscle tension\"})\n",
        "    training_data.append({\"class\":\"stress\", \"sentence\":\"pain restlessness\"})\n",
        "    training_data.append({\"class\":\"stress\", \"sentence\":\"angry outbursts\"})\n",
        "    training_data.append({\"class\":\"stress\", \"sentence\":\"chest pain\"})\n",
        "    training_data.append({\"class\":\"stress\", \"sentence\":\"lack of motivation\"})\n",
        "    training_data.append({\"class\":\"stress\", \"sentence\":\"drug or alchohol misuse\"})\n",
        "    training_data.append({\"class\":\"stress\", \"sentence\":\"fatigue\"})\n",
        "    training_data.append({\"class\":\"stress\", \"sentence\":\"feeling overwhelmed\"})\n",
        "    training_data.append({\"class\":\"stress\", \"sentence\":\"tobacco use\"})\n",
        "    training_data.append({\"class\":\"stress\", \"sentence\":\"change in sex drive\"})\n",
        "    training_data.append({\"class\":\"stress\", \"sentence\":\"easily to irritate or anger\"})\n",
        "    training_data.append({\"class\":\"stress\", \"sentence\":\"social withdrawal\"})\n",
        "    training_data.append({\"class\":\"stress\", \"sentence\":\"stomach upset\"})\n",
        "    training_data.append({\"class\":\"stress\", \"sentence\":\"sleep problem\"})"
      ],
      "metadata": {
        "id": "HJu-Zst-AdKn"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    print (\"%s sentences of training data\" % len(training_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmJOBOMNBH7b",
        "outputId": "1434b60a-6c3d-4e75-9dab-f2f3c3517729"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "95 sentences of training data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess():\n",
        "    nltk.download('punkt')\n",
        "    # turn a list into a set (of unique items) and then a list again (this removes duplicates)\n",
        "    classes = list(set([a['class'] for a in training_data]))\n",
        "    for c in classes:\n",
        "        # prepare a list of words within each class\n",
        "        class_words[c] = []\n",
        "\n",
        "    # loop through each sentence in our training data\n",
        "    for data in training_data:\n",
        "        # tokenize each sentence into words\n",
        "        for word in nltk.word_tokenize(data['sentence']):\n",
        "            # ignore a some things\n",
        "            if word not in [\"?\", \"'s\"]:\n",
        "                # stem and lowercase each word\n",
        "                stemmed_word = stemmer.stem(word.lower())\n",
        "                # have we not seen this word already?\n",
        "                if stemmed_word not in corpus_words:\n",
        "                    corpus_words[stemmed_word] = 1\n",
        "                else:\n",
        "                    corpus_words[stemmed_word] += 1\n",
        "\n",
        "                # add the word to our words in class list\n",
        "                class_words[data['class']].extend([stemmed_word])\n"
      ],
      "metadata": {
        "id": "2n3IF0rOBNwQ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    # we now have each stemmed word and the number of occurances of the word in our training corpus (the word's commonality)\n",
        "    print (\"Corpus words and counts: %s \\n\" % corpus_words)\n",
        "    # also we have all words in each class\n",
        "    print (\"Class words: %s\" % class_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOdQSFG2BbG-",
        "outputId": "b48d5a96-7b43-4000-bd8d-a7647a4f0a1e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corpus words and counts: {} \n",
            "\n",
            "Class words: {}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate a score for a given class taking into account word commonality\n",
        "def calculate_class_score(sentence, class_name, show_details=True):\n",
        "    score = 0\n",
        "    # tokenize each word in our new sentence\n",
        "    for word in nltk.word_tokenize(sentence):\n",
        "        # check to see if the stem of the word is in any of our classes\n",
        "        if stemmer.stem(word.lower()) in class_words[class_name]:\n",
        "            # treat each word with relative weight\n",
        "            score += (1 / corpus_words[stemmer.stem(word.lower())])\n",
        "\n",
        "            if show_details:\n",
        "                print (\"   match: %s (%s)\" % (stemmer.stem(word.lower()), 1 / corpus_words[stemmer.stem(word.lower())]))\n",
        "    return score"
      ],
      "metadata": {
        "id": "JY7dCVXbBmFy"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# return the class with highest score for sentence\n",
        "def classify(sentence):\n",
        "    high_class = None\n",
        "    high_score = 0\n",
        "    # loop through our classes\n",
        "    for c in class_words.keys():\n",
        "        # calculate score of sentence for each class\n",
        "        score = calculate_class_score(sentence, c, show_details=False)\n",
        "        # keep track of highest score\n",
        "        if score > high_score:\n",
        "            high_class = c\n",
        "            high_score = score\n",
        "\n",
        "    print(\"class:\",high_class,\"score:\",high_score)\n",
        "    return high_class"
      ],
      "metadata": {
        "id": "keASs2bTBrOk"
      },
      "execution_count": 20,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "classify.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}